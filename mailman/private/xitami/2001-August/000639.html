<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [Xitami] Sub directory access
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:xitami%40lists.xitami.org">
   <META NAME="robots" CONTENT="index,nofollow">
   
   <LINK REL="Previous"  HREF="000636.html">
   <LINK REL="Next"  HREF="000638.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Xitami] Sub directory access
   </H1>
    <B>Ewen McNeill
    </B> 
    <A HREF="mailto:xitami%40lists.xitami.org"
       TITLE="[Xitami] Sub directory access">xitami@lists.xitami.org
       </A><BR>
    <I>Fri, 10 Aug 2001 07:21:20 +1200</I>
    <P><UL>
        <LI> Previous message: <A HREF="000636.html">[Xitami] Sub directory access
</A></li>
        <LI> Next message: <A HREF="000638.html">[Xitami] Sub directory access
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#639">[ date ]</a>
              <a href="thread.html#639">[ thread ]</a>
              <a href="subject.html#639">[ subject ]</a>
              <a href="author.html#639">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>In message &lt;<A HREF="mailto:997380321@coconutcomm.com">997380321@coconutcomm.com</A>&gt;, <A HREF="mailto:john.uhlig@coconutcomm.com">john.uhlig@coconutcomm.com</A> writes:
&gt;<i>Hmm, maybe that is the problem - the &quot;index&quot; listing of all user pages are
</I>&gt;<i>created dynamically for every request, depending on the user input, i.e.
</I>&gt;<i>searching a particular region. I *assumed* that if I submitted the TLD to
</I>&gt;<i>search engines, that it would automatically get all subdirectories under that
</I>&gt;<i>domain. So what you are saying is that there should be a hard coded index page
</I>&gt;<i>with links to all of the directories/pages under the TLD?
</I>
Search engine spiders (the things that index pages) work by getting a
page (eg, the top level page) and then following the links in that, and
the links in the pages that gets to and the links in the pages that gets
to and...

If you've got a bunch of directories that _are_ links to from the index
page at the front, it'll find them fairly easily.  If you've got a bunch
of pages which aren't linked from there (and/or aren't linked from
anywhere but CGI scripts, which generally search engines will avoid
running) then it won't be able to find them, since it doesn't know to
look.

As someone else said, either rearrange your site so that there's a set
of links that leads there, or submit the URLs separately.

If a web browser can access the pages, so can an indexing spider.  The
question is &quot;does it know that it should&quot;?

Ewen

-- 
Ewen McNeill, Technical Consultant, iMatix Corporation  www.imatix.com

</PRE>
<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI> Previous message: <A HREF="000636.html">[Xitami] Sub directory access
</A></li>
	<LI> Next message: <A HREF="000638.html">[Xitami] Sub directory access
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#639">[ date ]</a>
              <a href="thread.html#639">[ thread ]</a>
              <a href="subject.html#639">[ subject ]</a>
              <a href="author.html#639">[ author ]</a>
         </LI>
       </UL>
</body></html>
